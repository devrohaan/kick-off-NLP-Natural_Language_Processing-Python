{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing: Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's analyze this tweet when Sir Alex Ferguson has undergone surgery for a brain haemorrhage.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tweet:\n",
    "\n",
    "\"Get well soon fergy lad &lt;3!!! u're a awsm legend. As a Man City fan ... I wish Sir Alex a speedy recovery &amp; send my best wishes to his family at this difficult time. #ManchesterCityFan#footballfan 💙💙\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Eliminating HTML characters: \n",
    "\n",
    "Data obtained from web usually contains a lot of html entities like &lt; &gt; &amp; which gets embedded in the original data. It is thus necessary to get rid of these entities.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unescape(s):\n",
    "    s = s.replace(\"&lt;\", \"<\")\n",
    "    s = s.replace(\"&gt;\", \">\")\n",
    "    s = s.replace(\"&amp;\", \"&\")\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned Tweet:  Get well soon fergy lad <3!!! u're a awsm legend. As a Man City fan ... I wish Sir Alex a speedy recovery & send my best wishes to his family at this difficult time. #ManchesterCityFan#footballfan 💙💙\n"
     ]
    }
   ],
   "source": [
    "inputTweet = \"Get well soon fergy lad &lt;3!!! u're a awsm legend. As a Man City fan ... I wish Sir Alex a speedy recovery &amp; send my best wishes to his family at this difficult time. #ManchesterCityFan#footballfan 💙💙\"\n",
    "outputTweet = unescape(inputTweet)\n",
    "print(\"Cleaned Tweet: \", outputTweet)\n",
    "\n",
    "#or\n",
    "\n",
    "import html\n",
    "inputTweet = html.unescape(inputTweet)\n",
    "#print(\"Cleaned Tweet: \", inputTweet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## 2. Data Decoding\n",
    "\n",
    "Text data may be subject to different forms of decoding like “Latin”, “UTF8” etc. Therefore, for better analysis, it is necessary to keep the complete data in standard encoding format. UTF-8 encoding is widely accepted and is recommended to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned Tweet:  Get well soon fergy lad <3!!! u're a awsm legend. As a Man City fan ... I wish Sir Alex a speedy recovery & send my best wishes to his family at this difficult time. #ManchesterCityFan#footballfan \n"
     ]
    }
   ],
   "source": [
    "inputTweet = inputTweet.encode('ascii', 'ignore').decode('utf-8', 'ignore')\n",
    "print(\"Cleaned Tweet: \", inputTweet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Expanding Apostrophe \n",
    "\n",
    "All the apostrophes should be converted into standard lexicons. One can use a lookup table of all possible keys to get rid of disambiguates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictApost = {\n",
    "    \"'s\" : \" is\",\n",
    "    \"you're\" : \"you are\",\n",
    "    \"u're\" : \"you are\",\n",
    "    \"can't\" : \" cannot\",\n",
    "    \"won't\" : \" will not\", \n",
    "    \"isn't\" : \" is not\", \n",
    "    \"it's\" : \" it is\", \n",
    "    \"o'clock\" : \" of the clock\"\n",
    "} ## Need a huge dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Get well soon fergy lad <3!!! you are a awsm legend. As a Man City fan ... I wish Sir Alex a speedy recovery & send my best wishes to his family at this difficult time. #ManchesterCityFan#footballfan\n"
     ]
    }
   ],
   "source": [
    "words = inputTweet.split()\n",
    "reformed = [dictApost[word] if word in dictApost else word for word in words]\n",
    "inputTweet = \" \".join(reformed)\n",
    "print(inputTweet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Remove of Punctuations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Get well soon fergy lad <3!!! you are a awsm legend. As a Man City fan ... I wish Sir Alex a speedy recovery & send my best wishes to his family at this difficult time. #ManchesterCityFan#footballfan\n",
      "Get well soon fergy lad 3 you are a awsm legend As a Man City fan  I wish Sir Alex a speedy recovery  send my best wishes to his family at this difficult time ManchesterCityFanfootballfan\n",
      "Get well soon fergy lad 3 you are a awsm legend As a Man City fan  I wish Sir Alex a speedy recovery  send my best wishes to his family at this difficult time ManchesterCityFanfootballfan\n"
     ]
    }
   ],
   "source": [
    "print(inputTweet)\n",
    "import re\n",
    "import string\n",
    "inputTweet1 = re.sub(r'[^\\w\\s]', '', inputTweet)\n",
    "print(inputTweet1)\n",
    "\n",
    "table = str.maketrans({key: None for key in string.punctuation})\n",
    "inputTweet = inputTweet.translate(table)\n",
    "print(inputTweet)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Remove of Email-IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My name is CR7 \n"
     ]
    }
   ],
   "source": [
    "string  = 'My name is CR7 wisdomic@panda.com'\n",
    "pattern = r\"\\w+@[a-z]+\\.[a-z]+\"\n",
    "regex = re.compile(pattern)\n",
    "listobj = regex.sub('',string)\n",
    "print(listobj)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Standardizing Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "lookup_dict = {\n",
    "    'awsm':'awesome',\n",
    "    'lol' : 'laughing out loud',\n",
    "    'brb':'be right back',\n",
    "    'btw':'by the way',\n",
    "    'lmk':'let me know',\n",
    "    'g2g':'got to go',\n",
    "    'rt':'retweet',\n",
    "    'dm':'direct message',\n",
    "    \"awsm\" : \"awesome\",\n",
    "    \"luv\" :\"love\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Standardize(input_text):\n",
    "    words = input_text.split() \n",
    "    new_words = []\n",
    "    new_text = []\n",
    "    for word in words:\n",
    "        if word.lower() in lookup_dict:\n",
    "            word = lookup_dict[word.lower()]\n",
    "            new_words.append(word)\n",
    "        else:\n",
    "            new_words.append(word)\n",
    "    return \" \".join(new_words) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Get well soon fergy lad 3 you are a awesome legend As a Man City fan I wish Sir Alex a speedy recovery send my best wishes to his family at this difficult time ManchesterCityFanfootballfan\n"
     ]
    }
   ],
   "source": [
    "print(Standardize(inputTweet))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.  Remove Non-ASCII Characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def remove_non_ascii(words):\n",
    "    \n",
    "    list_of_words = []\n",
    "    for wordlist in words:\n",
    "        wordlist = [unicodedata.normalize('NFKD', word).encode('ascii', 'ignore').decode('utf-8', 'ignore') for word in wordlist]\n",
    "        list_of_words.append(wordlist)\n",
    "    return list_of_words\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Spelling Correction\n",
    "\n",
    "Spelling correction is a useful pre-processing step because this also will help us in reducing multiple copies of words. For example, “Analytics” and “analytcs” will be treated as different words even if they are used in the same sense."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "science and technology\n"
     ]
    }
   ],
   "source": [
    "from textblob import TextBlob\n",
    "blob = TextBlob(\"sciemce amd teknology\")\n",
    "print(blob.correct())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
